{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "import networkx as nx\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import streamlit as st\n",
    "from annotated_text import annotated_text, parameters\n",
    "from streamlit_extras import add_vertical_space as avs\n",
    "from streamlit_extras.badges import badge\n",
    "from scripts.similarity import get_similarity_score, find_path, read_config\n",
    "from scripts.utils import get_filenames_from_dir\n",
    "from scripts import ReadPdf, JobDescriptionProcessor, ResumeProcessor, KeytermsExtraction\n",
    "import cohere\n",
    "from scripts.KeytermsExtraction import KeytermExtractor\n",
    "from scripts.similarity.get_similarity_score import get_similarity_score\n",
    "import uuid\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    filename='app_similarity_score.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "console_handler.setFormatter(formatter)\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "file_handler = logging.FileHandler(\"app_similarity_score.log\")\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "cwd = find_path('Resume-Matcher')\n",
    "config_path = os.path.join(cwd, \"scripts\", \"similarity\")\n",
    "\n",
    "\n",
    "def read_config(filepath):\n",
    "    try:\n",
    "        with open(filepath) as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        return config\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"Configuration file {filepath} not found: {e}\")\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(\n",
    "            f\"Error parsing YAML in configuration file {filepath}: {e}\", exc_info=True)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading configuration file {filepath}: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "config = read_config(config_path + \"/config.yml\")\n",
    "PROJECT_ID = config['vertex']['api_key']\n",
    "REGION = config['vertex']['REGION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_STACK = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "job_desc_directory = \"Data/JobDescription/\"\n",
    "resumes_directory = \"Data/Resumes/\"\n",
    "\n",
    "# Automatically get all job description and resume files\n",
    "job_desc_files = [file for file in os.listdir(\n",
    "    job_desc_directory) if file.endswith('.pdf')]\n",
    "resume_files = [file for file in os.listdir(\n",
    "    resumes_directory) if file.endswith('.pdf')]\n",
    "\n",
    "# This will select the first job description file\n",
    "job_desc_file = job_desc_files[FULL_STACK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect your MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose or create a database named 'resume_db'\n",
    "db = client['resume_db']\n",
    "\n",
    "# Choose or create a collection named 'candidates'\n",
    "candidates_collection = db['candidates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose or create a database named 'job_db'\n",
    "db = client['job_db']\n",
    "job_collection = db['job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "# Read raw job description\n",
    "# job_desc_text = ReadPdf.read_single_pdf(\"Data/JobDescription/\" + job_desc_file)\n",
    "job_desc_text = [ReadPdf.read_single_pdf(os.path.join(\n",
    "    \"Data/JobDescription/\", job_desc_file)) for job_desc_file in job_desc_files]\n",
    "# Process job description\n",
    "job_desc_processor = JobDescriptionProcessor(job_desc_file)\n",
    "job_desc_processed = job_desc_processor._read_job_desc()\n",
    "\n",
    "job_files = [f for f in o s.listdir(\n",
    "    \"Data/JobDescription/\") if os.path.isfile(os.path.join(\"Data/JobDescription/\", f))]\n",
    "\n",
    "\n",
    "job_processed = []\n",
    "for job_file in job_files:\n",
    "    job_processor = JobDescriptionProcessor(job_file)\n",
    "    job_data = job_processor._read_job_desc()\n",
    "    job_processor._write_json_file(job_data)\n",
    "    job_processed.append(job_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job_desc_full_stack_engineer.pdf',\n",
       " 'job_desc_front_end_engineer.pdf',\n",
       " 'job_desc_java_developer.pdf',\n",
       " 'job_desc_product_manager.pdf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unique_id': '2e3cb665-8a86-40d0-b721-2fc4114c04d3',\n",
       " 'job_desc_data': 'Job Description: Senior Full Stack Engineer (5+ Years of\\nExperience)\\nTech Solutions, San Francisco, CA, USA\\nAbout Us\\nTech Solutions is a leading technology company that creates innovative solutions across a variety of industries.\\nOur mission is to improve lives through advanced technology. We’re currently seeking a Senior Full Stack\\nEngineer to join our dynamic team.\\nJob Description\\nWe’re looking for a Senior Full Stack Engineer with 5+ years of experience in developing web applications.\\nThe successful candidate will have experience working with both front-end and back-end technologies, and\\nwill be capable of overseeing projects from conception to production deployment.\\nResponsibilities\\n•Developing front end website architecture.\\n•Designing user interactions on web pages.\\n•Developing back end website applications.\\n•Creating servers and databases for functionality.\\n•Ensuring cross-platform optimization for mobile phones.\\n•Seeing through a project from conception to finished product.\\n•Designing and developing APIs.\\n•Meeting both technical and consumer needs.\\n•Staying abreast of developments in web applications and programming languages.\\nRequirements\\n•Degree in Computer Science or similar field.\\n•5+ years of experience in web development.\\n•Strong organizational and project management skills.\\n•Proficiency with fundamental front end languages such as HTML, CSS, and JavaScript.\\n•Proficiency with server-side languages such as Python, Ruby, Java, PHP, and .Net.\\n•Familiarity with database technology such as MySQL, Oracle, and MongoDB.\\n1 •Excellent verbal communication skills.\\n•Good problem-solving skills.\\n•Attention to detail.\\nBenefits\\n•Competitive salary package.\\n•Health, dental, and vision insurance.\\n•Retirement savings plan.\\n•Professional development opportunities.\\n•Flexible work hours.\\nTech Solutions is an equal opportunity employer and we value diversity at our company.\\nHow to Apply\\nTo apply, please submit your resume and a brief explanation of your relevant experience to hiring@techsolutions.com .\\n2',\n",
       " 'clean_data': 'Job Description Senior Full Stack Engineer 5+ Years of\\nExperience\\nTech Solutions San Francisco CA USA\\nAbout Us\\nTech Solutions is a leading technology company that creates innovative solutions across a variety of industries\\nOur mission is to improve lives through advanced technology We’re currently seeking a Senior Full Stack\\nEngineer to join our dynamic team\\nJob Description\\nWe’re looking for a Senior Full Stack Engineer with 5+ years of experience in developing web applications\\nThe successful candidate will have experience working with both frontend and backend technologies and\\nwill be capable of overseeing projects from conception to production deployment\\nResponsibilities\\n•Developing front end website architecture\\n•Designing user interactions on web pages\\n•Developing back end website applications\\n•Creating servers and databases for functionality\\n•Ensuring crossplatform optimization for mobile phones\\n•Seeing through a project from conception to finished product\\n•Designing and developing APIs\\n•Meeting both technical and consumer needs\\n•Staying abreast of developments in web applications and programming languages\\nRequirements\\n•Degree in Computer Science or similar field\\n•5+ years of experience in web development\\n•Strong organizational and project management skills\\n•Proficiency with fundamental front end languages such as HTML CSS and JavaScript\\n•Proficiency with serverside languages such as Python Ruby Java PHP and Net\\n•Familiarity with database technology such as MySQL Oracle and MongoDB\\n1 •Excellent verbal communication skills\\n•Good problemsolving skills\\n•Attention to detail\\nBenefits\\n•Competitive salary package\\n•Health dental and vision insurance\\n•Retirement savings plan\\n•Professional development opportunities\\n•Flexible work hours\\nTech Solutions is an equal opportunity employer and we value diversity at our company\\nHow to Apply\\nTo apply please submit your resume and a brief explanation of your relevant experience to  \\n2',\n",
       " 'entities': ['Tech Solutions',\n",
       "  'Python Ruby Java PHP',\n",
       "  'JavaScript',\n",
       "  '•5',\n",
       "  'San Francisco',\n",
       "  'Us',\n",
       "  'HTML CSS'],\n",
       " 'extracted_keywords': ['Job',\n",
       "  'Description',\n",
       "  'Senior',\n",
       "  'Full',\n",
       "  'Stack',\n",
       "  'Engineer',\n",
       "  'Years',\n",
       "  'Experience',\n",
       "  'Tech',\n",
       "  'Solutions',\n",
       "  'San',\n",
       "  'Francisco',\n",
       "  'CA',\n",
       "  'USA',\n",
       "  'Us',\n",
       "  'Tech',\n",
       "  'Solutions',\n",
       "  'technology',\n",
       "  'company',\n",
       "  'solutions',\n",
       "  'variety',\n",
       "  'industries',\n",
       "  'mission',\n",
       "  'lives',\n",
       "  'technology',\n",
       "  'Senior',\n",
       "  'Full',\n",
       "  'Stack',\n",
       "  'Engineer',\n",
       "  'team',\n",
       "  'Job',\n",
       "  'Description',\n",
       "  'Senior',\n",
       "  'Full',\n",
       "  'Stack',\n",
       "  'Engineer',\n",
       "  'years',\n",
       "  'experience',\n",
       "  'web',\n",
       "  'applications',\n",
       "  'candidate',\n",
       "  'experience',\n",
       "  'frontend',\n",
       "  'technologies',\n",
       "  'projects',\n",
       "  'conception',\n",
       "  'production',\n",
       "  'deployment',\n",
       "  'Responsibilities',\n",
       "  'end',\n",
       "  'website',\n",
       "  'architecture',\n",
       "  '•Designing',\n",
       "  'user',\n",
       "  'interactions',\n",
       "  'web',\n",
       "  'pages',\n",
       "  'end',\n",
       "  'website',\n",
       "  'applications',\n",
       "  'servers',\n",
       "  'databases',\n",
       "  'functionality',\n",
       "  'crossplatform',\n",
       "  'optimization',\n",
       "  'phones',\n",
       "  'project',\n",
       "  'conception',\n",
       "  'product',\n",
       "  '•Designing',\n",
       "  'APIs',\n",
       "  'consumer',\n",
       "  'needs',\n",
       "  '•Staying',\n",
       "  'developments',\n",
       "  'web',\n",
       "  'applications',\n",
       "  'programming',\n",
       "  'languages',\n",
       "  'Requirements',\n",
       "  'Computer',\n",
       "  'Science',\n",
       "  'field',\n",
       "  '•5',\n",
       "  'years',\n",
       "  'experience',\n",
       "  'web',\n",
       "  'development',\n",
       "  '•Strong',\n",
       "  'project',\n",
       "  'management',\n",
       "  'skills',\n",
       "  '•Proficiency',\n",
       "  'end',\n",
       "  'languages',\n",
       "  'HTML',\n",
       "  'CSS',\n",
       "  'JavaScript',\n",
       "  '•Proficiency',\n",
       "  'serverside',\n",
       "  'languages',\n",
       "  'Python',\n",
       "  'Ruby',\n",
       "  'Java',\n",
       "  'PHP',\n",
       "  'Net',\n",
       "  '•Familiarity',\n",
       "  'database',\n",
       "  'technology',\n",
       "  'MySQL',\n",
       "  'Oracle',\n",
       "  'MongoDB',\n",
       "  'communication',\n",
       "  'skills',\n",
       "  '•Attention',\n",
       "  'Benefits',\n",
       "  'salary',\n",
       "  'package',\n",
       "  '•Health',\n",
       "  'vision',\n",
       "  'insurance',\n",
       "  'savings',\n",
       "  'plan',\n",
       "  'development',\n",
       "  'opportunities',\n",
       "  'work',\n",
       "  'hours',\n",
       "  'Tech',\n",
       "  'Solutions',\n",
       "  'opportunity',\n",
       "  'employer',\n",
       "  'diversity',\n",
       "  'company',\n",
       "  'resume',\n",
       "  'explanation',\n",
       "  'experience'],\n",
       " 'keyterms': [('Senior Full stack', 0.36734547073779045),\n",
       "  ('Job Description', 0.1137969836501915),\n",
       "  ('Tech Solutions', 0.08785209480327773),\n",
       "  ('experience', 0.0402594489684917),\n",
       "  ('web application', 0.031091464413874694),\n",
       "  ('technology', 0.026103226555550127),\n",
       "  ('end website', 0.02603264785474888),\n",
       "  ('year', 0.02280185463098348),\n",
       "  ('Engineer', 0.015158334006474023),\n",
       "  ('company', 0.01299126818329351),\n",
       "  ('project', 0.008025371467830188),\n",
       "  ('development', 0.006199971245814812),\n",
       "  ('database', 0.005431870607290941),\n",
       "  ('conception', 0.005159537892195308),\n",
       "  ('language', 0.004950592066886817),\n",
       "  ('solution', 0.004909896555990972),\n",
       "  ('innovative', 0.004862122886957498),\n",
       "  ('Francisco', 0.004742057116465734),\n",
       "  ('variety', 0.004727628158636155),\n",
       "  ('San', 0.004700569886380095)],\n",
       " 'bi_grams': '[Job Description, Description Senior, Stack Engineer, + Years, Tech Solutions, Solutions San, San Francisco, Tech Solutions, leading technology, technology company, creates innovative, innovative solutions, improve lives, advanced technology, currently seeking, dynamic team, Job Description, Stack Engineer, + years, developing web, web applications, successful candidate, experience working, backend technologies, overseeing projects, production deployment, end website, website architecture, •Designing user, user interactions, web pages, end website, website applications, •Creating servers, •Ensuring crossplatform, crossplatform optimization, mobile phones, finished product, developing APIs, consumer needs, •Staying abreast, web applications, programming languages, Computer Science, similar field, •5+, + years, web development, •Strong organizational, project management, management skills, end languages, HTML CSS, serverside languages, Python Ruby, Ruby Java, Java PHP, database technology, MySQL Oracle, •Excellent verbal, verbal communication, communication skills, •Good problemsolving, problemsolving skills, •Competitive salary, salary package, •Health dental, vision insurance, •Retirement savings, savings plan, •Professional development, development opportunities, •Flexible work, work hours, Tech Solutions, equal opportunity, opportunity employer, value diversity, brief explanation, relevant experience]',\n",
       " 'tri_grams': '[Job Description Senior, Senior Full Stack, Tech Solutions San, Solutions San Francisco, Francisco CA USA, leading technology company, company that creates, creates innovative solutions, variety of industries, lives through advanced, seeking a Senior, Senior Full Stack, Engineer to join, join our dynamic, Senior Full Stack, years of experience, experience in developing, developing web applications, frontend and backend, capable of overseeing, projects from conception, conception to production, •Developing front end, end website architecture, •Designing user interactions, interactions on web, •Developing back end, end website applications, servers and databases, databases for functionality, •Ensuring crossplatform optimization, optimization for mobile, project from conception, conception to finished, •Designing and developing, •Meeting both technical, technical and consumer, abreast of developments, developments in web, applications and programming, •Degree in Computer, Science or similar, •5+ years, years of experience, experience in web, organizational and project, project management skills, •Proficiency with fundamental, fundamental front end, CSS and JavaScript, •Proficiency with serverside, Python Ruby Java, Ruby Java PHP, PHP and Net, •Familiarity with database, Oracle and MongoDB, •Excellent verbal communication, verbal communication skills, •Good problemsolving skills, •Attention to detail, •Competitive salary package, dental and vision, •Retirement savings plan, •Professional development opportunities, •Flexible work hours, equal opportunity employer, apply please submit, submit your resume]',\n",
       " 'pos_frequencies': {'PROPN': 38,\n",
       "  'NUM': 5,\n",
       "  'SYM': 2,\n",
       "  'NOUN': 99,\n",
       "  'ADP': 33,\n",
       "  'SPACE': 40,\n",
       "  'AUX': 8,\n",
       "  'DET': 8,\n",
       "  'VERB': 25,\n",
       "  'PRON': 9,\n",
       "  'ADJ': 28,\n",
       "  'PART': 5,\n",
       "  'ADV': 1,\n",
       "  'CCONJ': 16,\n",
       "  'INTJ': 2,\n",
       "  'SCONJ': 1}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resumes_text = [ReadPdf.read_single_pdf(os.path.join(\n",
    "    \"Data/Resumes/\", resume_file)) for resume_file in resume_files]\n",
    "\n",
    "\n",
    "# Process resumes\n",
    "resume_files = [f for f in os.listdir(\n",
    "    \"Data/Resumes/\") if os.path.isfile(os.path.join(\"Data/Resumes/\", f))]\n",
    "\n",
    "resumes_processed = []\n",
    "for resume_file in resume_files:\n",
    "    resume_processor = ResumeProcessor(resume_file)\n",
    "    resume_data = resume_processor._read_resumes()\n",
    "    resume_processor._write_json_file(resume_data)\n",
    "    resumes_processed.append(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_name_from_filename(filename: str) -> str:\n",
    "    # Exclude the last part which is the position\n",
    "    name_parts = filename.split('_')[:-1]\n",
    "    return ' '.join(name_parts).title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names = [extract_candidate_name_from_filename(\n",
    "    resume_file) for resume_file in resume_files]\n",
    "candidate_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resumes_processed[0]['name']\n",
    "\n",
    "for i in range(len(resumes_processed)):\n",
    "    resumes_processed[i]['name'] = candidate_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_collection.insert_many(resumes_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jobdes_name_from_filename(filename: str) -> str:\n",
    "    # Exclude the last part which is the position\n",
    "    name_parts = filename.split('_')[:-1]\n",
    "    return ' '.join(name_parts).title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_des = [extract_jobdes_name_from_filename(\n",
    "    job_desc_file) for job_desc_file in job_desc_files]\n",
    "job_des = [item.replace('Job Desc ', '') for item in job_des]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(job_processed)):\n",
    "    job_processed[i].update({'job_title': job_des[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_collection.insert_many(job_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_des_parse_data = job_collection.find({}, {'unique_id':1,'clean_data':1,'extracted_keywords':1,'_id':0,'job_title':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_des_parse_data = list(job_des_parse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_to_index = {}\n",
    "job_unique_id = []\n",
    "\n",
    "for index, data in enumerate(job_des_parse_data):\n",
    "    # Convert the job_title to uppercase and replace spaces with underscores\n",
    "    constant_name = data['job_title'].upper().replace(' ', '_')\n",
    "    job_unique_id.append(data['unique_id'])\n",
    "    # Set the constant name as a key in the dictionary with its index as the value\n",
    "    job_title_to_index[constant_name] = index\n",
    "\n",
    "# To access a particular index:\n",
    "# index_for_full_stack = job_title_to_index['FULL_STACK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the candidates from the MongoDB collection\n",
    "candidates_parse_data = candidates_collection.find(\n",
    "    {}, {\"name\": 1, \"unique_id\": 1, \"_id\": 0, \"clean_data\": 1, \"extracted_keywords\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_parse_data = list(candidates_parse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_parse_data_holder = candidates_parse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_unique_id = []\n",
    "\n",
    "for index, data in enumerate(candidates_parse_data):\n",
    "    # Convert the job_title to uppercase and replace spaces with underscores\n",
    "    candidates_unique_id.append(data['unique_id'])\n",
    "    # Set the constant name as a key in the dictionary with its index as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list for resumes_keywords if it doesn't exist yet\n",
    "\n",
    "\n",
    "# Iterate over the cursor and update resumes_keywords\n",
    "# Initialize an empty list for resumes_keywords if it doesn't exist yet\n",
    "# Initialize an empty list for resumes_keywords if it doesn't exist yet\n",
    "resumes_keywords_str_list = []\n",
    "\n",
    "# Iterate over the cursor and update resumes_keywords\n",
    "for document in candidates_parse_data_holder:\n",
    "    keyword_string = ' '.join(document['extracted_keywords'])\n",
    "    resumes_keywords_str_list.append(keyword_string)\n",
    "    # resumes_keywords.append(document['extracted_keywords'])\n",
    "\n",
    "\n",
    "# for index in range(len(candidates_parse_data)):\n",
    "#     candidates_parse_data[index]['extracted_keywords'] = resumes_keywords[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes_clean_data_str_list = []\n",
    "\n",
    "# Iterate over the cursor and update resumes_keywords\n",
    "for document in candidates_parse_data:\n",
    "    keyword_string = ' '.join(document['clean_data'])\n",
    "    resumes_clean_data_str_list.append(keyword_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the extracted keywords into strings\n",
    "# job_desc_keywords_str = ' '.join([keyword[0] for keyword in job_desc_keywords])\n",
    "job_desc_keywords_str_list = []\n",
    "for index in range(len(job_des_parse_data)):\n",
    "    keyword_string = ' '.join(document['extracted_keywords'])\n",
    "    job_desc_keywords_str_list.append(keyword_string)\n",
    "    #job_desc_keywords_str_list.append(job_des_parse_data[index]['clean_data'])\n",
    "    #job_desc_keywords_str_list.append(job_des_parse_data[index]['extracted_keywords'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names = [extract_candidate_name_from_filename(\n",
    "    resume_file) for resume_file in resume_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_desc_embeddings = embeddings.embed_documents(job_desc_keywords_str_list)\n",
    "# Assuming job_desc_keywords_str_list is a list of lists\n",
    "# flattened_list = [\n",
    "#     item for sublist in job_desc_keywords_str_list for item in sublist]\n",
    "\n",
    "# Now, each element of flattened_list should be a string\n",
    "job_desc_embeddings = embeddings.embed_documents(job_desc_keywords_str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes_embeddings = embeddings.embed_documents(resumes_keywords_str_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect your Pinecone database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "\tapi_key= config['pinecone']['api_key'],\n",
    "\tenvironment='gcp-starter'\n",
    ")\n",
    "\n",
    "index = pinecone.Index(index_name=\"jobmatcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_for_full_stack = job_title_to_index['FULL_STACK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_des_underscore = [name.replace(' ', '_') for name in job_des]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names_underscore = [name.replace(\n",
    "    ' ', '_') for name in candidate_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_desc_embeddings), len(job_des_underscore), len(job_unique_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_vectors_with_metadata = []\n",
    "\n",
    "# for i, embedding in enumerate(job_desc_embeddings):\n",
    "#     vector_data = {\n",
    "#         \"id\": job_des_underscore[i:4],\n",
    "#         \"values\": embedding,\n",
    "#         \"metadata\": {\"unique_id\": job_unique_id[i]}\n",
    "#     }\n",
    "#     job_vectors_with_metadata.append(vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, embedding in enumerate(job_desc_embeddings):\n",
    "    if i < len(job_des_underscore) and i < len(job_unique_id):\n",
    "        vector_data = {\n",
    "            \"id\": job_des_underscore[i],\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": {\"unique_id\": job_unique_id[i]}\n",
    "        }\n",
    "        job_vectors_with_metadata.append(vector_data)\n",
    "    else:\n",
    "        break  # Break the loop if i exceeds the length of other lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_vectors_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_vectors_with_metadata = []\n",
    "\n",
    "# for i, embedding in enumerate(resumes_embeddings):\n",
    "#     vector_data = {\n",
    "#        \"id\": candidate_names_underscore[i:4],\n",
    "#         \"values\": embedding,\n",
    "#         \"metadata\": {\"unique_id\": candidates_unique_id[i]}\n",
    "#     }\n",
    "#     candidates_vectors_with_metadata.append(vector_data)\n",
    "for i, embedding in enumerate(resumes_embeddings):\n",
    "    if i < len(candidate_names_underscore) and i < len(candidates_unique_id):\n",
    "        vector_data = {\n",
    "            \"id\": candidate_names_underscore[i],\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": {\"unique_id\": candidates_unique_id[i]}\n",
    "        }\n",
    "        candidates_vectors_with_metadata.append(vector_data)\n",
    "    else:\n",
    "        break  # Break the loop if i exceeds the length of other lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors_with_metadata = job_vectors_with_metadata + candidates_vectors_with_metadata\n",
    "index.upsert(vectors=all_vectors_with_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_fetched_vectors = index.fetch(ids=candidate_names_underscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_fetched_vectors = index.fetch(ids=job_des_underscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_job_vectors = {}\n",
    "\n",
    "for name, data in jobs_fetched_vectors['vectors'].items():\n",
    "    all_job_vectors[name] = data['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_candidate_vectors = {}\n",
    "\n",
    "for name, data in candidates_fetched_vectors['vectors'].items():\n",
    "    all_candidate_vectors[name] = data['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_job_vectors['Full_Stack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_cosine_similarity(embedding1: List[float], embedding2: List[float]) -> float:\n",
    "    similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "similarities_with_names = []\n",
    "\n",
    "# Assuming all_job_vectors['Full_Stack'] gives you the vector for the 'Full_Stack' job.\n",
    "full_stack_vector = all_job_vectors['Full_Stack']\n",
    "\n",
    "for candidate_name, candidate_vector in all_candidate_vectors.items():\n",
    "    similarity_score = cosine_similarity(\n",
    "        [full_stack_vector], [candidate_vector])[0][0]\n",
    "    similarities_with_names.append({\n",
    "        \"name\": candidate_name,\n",
    "        \"similarity\": similarity_score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_candidates = sorted(similarities_with_names,\n",
    "                           key=lambda x: x[\"similarity\"], reverse=True)\n",
    "\n",
    "# Print the ranked candidates\n",
    "# Starting the index from 1\n",
    "for index, candidate in enumerate(ranked_candidates, 1):\n",
    "    print(\n",
    "        f\"Candidate {index}: {candidate['name']}, Similarity Score: {candidate['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Set the file path\n",
    "file_path = 'Data/Result/ranked_candidates_hugging.csv'\n",
    "\n",
    "# Prepare the data for CSV\n",
    "rows = [[\"Rank\", \"Candidate Name\", \"Similarity Score\"]]\n",
    "for index, candidate in enumerate(ranked_candidates, 1):\n",
    "    rows.append([index, candidate['name'], candidate['similarity']])\n",
    "\n",
    "# Save to CSV\n",
    "with open(file_path, \"w\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
